import os
import glob
import re
import copy
import shutil
import boto3
from botocore.exceptions import NoCredentialsError
import datetime
import shelve
import streamlit as st
import numpy as np
import pandas as pd
from pathlib import Path
from PIL import Image


@st.cache
def list_imagespath(image_dir):
    images_fullpath = glob.glob(os.path.join(image_dir, "*"))
    images_fullpath = [folder for folder in images_fullpath if os.path.isdir(folder)]
    images_path = [os.path.basename(folder) for folder in images_fullpath]
    images_path.sort()
    return images_path


def list_imagespath_nonCache(image_dir):
    """ ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸ç”¨ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹ç‰ˆï¼‰
    """
    images_fullpath = glob.glob(os.path.join(image_dir, "*"))
    images_fullpath = [folder for folder in images_fullpath if os.path.isdir(folder)]
    images_path = [os.path.basename(folder) for folder in images_fullpath]
    images_path.sort()
    return images_path


# @st.cache
def list_images(target_dir):
    base_images = glob.glob(target_dir + "/*.jpg")
    base_images.sort()
    return base_images


@st.cache
def get_dir_list(path):
    dir_path = Path(path)
    dir_obj_list = [path for path in dir_path.glob("*") if path.is_dir() and not path.name.startswith(".")]
    dir_list = [image_obj.name for image_obj in dir_obj_list]
    dir_list.sort()
    return dir_list


@st.cache
def get_file_list(path):
    dir_path = Path(path)
    image_obj_list = [path for path in dir_path.glob("*") if path.is_file()]
    image_list = [image_obj.name for image_obj in image_obj_list]
    image_list.sort()
    return image_list


@st.cache
def read_markdown_file(markdown_file):
    return Path(markdown_file).read_text()


@st.cache
def read_python_file(python_file):
    return Path(python_file).read_text()


@st.cache
def get_file_content_as_string(filename):
    st.code(filename)


@st.cache
def ohc_image_load(base_images, idx, caption):
    st.text(f'{idx}ç•ªç›®ã®ç”»åƒã‚’è¡¨ç¤ºã—ã¾ã™')
    im_base = Image.open(base_images[idx])
    st.image(im_base, caption=caption)
    return im_base


@st.cache
def rail_name_to_jp(rail_name, config):
    return config.rail_names[rail_name]


@st.cache
def station_name_to_jp(st_name, config):
    return config.station_names[st_name]


@st.cache
def rail_type_to_jp(rail_type, config):
    return config.rail_type_names[rail_type]


@st.cache
def rail_type_name_to_jp(time_band_names, config):
    return config.time_band_names[time_band_names]


@st.cache
def camera_num_to_name(camera_num, config):
    return config.camera_names[camera_num]


# @st.cache
def rail_message(dir_area, config):
    str_list = re.split('[_-]', dir_area)
    rail_name = rail_name_to_jp(str_list[0], config)
    if str_list[3] == 'St':
        st_name = station_name_to_jp(str_list[2], config) + 'æ§‹å†…'
    else:
        st_name = station_name_to_jp(str_list[2], config) + 'ï½' + station_name_to_jp(str_list[3], config)
    updown_name = rail_type_to_jp(str_list[4], config)
    date_obj = datetime.datetime.strptime(str_list[5], "%Y%m%d")
    measurement_date = date_obj.strftime("%Yå¹´%mæœˆ%dæ—¥")    # # yyyyå¹´mmæœˆddæ—¥å½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›
    measurement_time = rail_type_name_to_jp(str_list[6], config)
    return rail_name, st_name, updown_name, measurement_date, measurement_time


@st.cache
def rail_camera_initialize(rail, camera_num, base_images, trolley_ids):
    """ railã«æ›¸ãè¾¼ã‚ã‚‹ã‚ˆã†ã«åˆæœŸåŒ–ã™ã‚‹
        è§£æçµæœãŒæ—¢ã«ã‚ã‚‹å ´åˆã¯åˆæœŸåŒ–ã—ãªã„
    Args:
        rail (shelve): è§£æçµæœä¿å­˜ç”¨ã®shelveãƒ•ã‚¡ã‚¤ãƒ«
        camera_num (str): ã‚«ãƒ¡ãƒ©ç•ªå·
        base_images (str): ç”»åƒã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        trolley_ids (str): trolley_idã®ãƒ†ãƒ³ãƒ—ãƒ¬ (trolley1, trolley2 ...)
    """
    if len(rail) < 2:    # åˆã‚ã¦railãŒç”Ÿæˆã•ã‚ŒãŸå ´åˆã¯"name"ã ã‘ãªã®ã§len(rail)ã¯1
        rail_check = False
    else:    # ä¸€åº¦ã§ã‚‚è§£æã•ã‚Œã‚‹ã¨trolley1,2,3ãŒè¿½åŠ ã•ã‚Œã‚‹ãŸã‚3ä»¥ä¸Š
        rail_check = any(len(rail[camera_num][image_path]) > 2 for image_path in base_images)
    if not rail_check:
        print('rail initilize')
        # railã‚’åˆæœŸåŒ–
        # base_imagesã¨åŒã˜é•·ã•ã®ç©ºã®dictionaryã‚’ä½œæˆã—ã¦railã‚’åˆæœŸåŒ–
        blankdict_size = [{}] * len(base_images)
        rail[camera_num] = dict(zip(base_images, blankdict_size))
        # trolley_idsã¨åŒã˜é•·ã•ã®ç©ºã®dictionaryã‚’ä½œæˆã—ã¦railã‚’åˆæœŸåŒ–
        blankdict_size = [{}] * len(trolley_ids)
        for image_path in base_images:
            rail[camera_num][image_path] = dict(zip(trolley_ids, blankdict_size))
    return


# @st.experimental_singleton(show_spinner=True)
def get_s3_dir_list(path):
    """ S3ãƒã‚±ãƒƒãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§ã‚’å–å¾—ã™ã‚‹
    Args:
        path (str): backetå†…ã®ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå(ä¾‹)imgs
    """
    backet_name = "trolley-monitor"
    
    s3 = boto3.client('s3')
    rail_list = []
    # S3ãƒã‚±ãƒƒãƒˆå†…ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§ã‚’å–å¾—
    response = s3.list_objects_v2(Bucket=backet_name, Prefix=path + "/" , Delimiter='/')
    for content in response.get('CommonPrefixes', []):
        full_path = content.get('Prefix')
        normalized_path = os.path.normpath(full_path)
        rail_list.append(os.path.basename(normalized_path))
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒ1000ä»¶æœªæº€ã«ãªã‚‹ã¾ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç¶šã‘ã‚‹
    while response['IsTruncated']:
        response = s3.list_objects_v2(Bucket=backet_name, Prefix=path + "/" , Delimiter='/', ContinuationToken=response['NextContinuationToken'])
        for content in response.get('CommonPrefixes', []):
            full_path = content.get('Prefix')
            normalized_path = os.path.normpath(full_path)
            rail_list.append(os.path.basename(normalized_path))
    rail_list.sort()
    return rail_list


def get_s3_image_list(path):
    """ S3ãƒã‚±ãƒƒãƒˆã®ã‚«ãƒ¡ãƒ©ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ã™ã‚‹
    Args:
        path (str): backetã‚’èµ·ç‚¹ã¨ã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ãƒ‘ã‚¹
                    (ä¾‹)images/Chuo_01_Tokyo-St_20230201_knight/HD11/
    """
    backet_name = "trolley-monitor"
    
    s3 = boto3.client('s3')
    image_list = []
    
    # S3ãƒã‚±ãƒƒãƒˆå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
    response = s3.list_objects_v2(Bucket=backet_name, Prefix=path + "/")
    for content in response.get('Contents', []):
        full_path = content.get('Key')
        image_list.append(os.path.basename(full_path))
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒ1000ä»¶æœªæº€ã«ãªã‚‹ã¾ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç¶šã‘ã‚‹
    while response['IsTruncated']:
        response = s3.list_objects_v2(Bucket=backet_name, Prefix=path + "/", ContinuationToken=response['NextContinuationToken'])
        for content in response.get('Contents', []):
            full_path = content.get('Key')
            image_list.append(os.path.basename(full_path))
    image_list.sort()
    return image_list


# @st.experimental_singleton(show_spinner=True)
def get_file_content_as_string(img_dir_name, path):
    """ S3ãƒã‚±ãƒƒãƒˆã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¦ãã‚‹
    Args:
        img_dir_name (str): backetå†…ã®ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå(ä¾‹)imgs/
        path (str): ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåå†…ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå(ä¾‹)Chuo_01_Tokyo-St_20230201_knight/
    """
    backet_name = "trolley-monitor"
    dir_path = img_dir_name + path
    
    s3 = boto3.resource('s3')
    response = s3.Object(backet_name, dir_path).get()['Body']
    return response.read().decode("utf-8")


def download_dir(prefix, local):
    """ ãƒã‚±ãƒƒãƒˆå†…ã®æŒ‡å®šã—ãŸãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’æŒã¤ã™ã¹ã¦ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    Args:
        prefix (str): S3ã®ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹
                      (ä¾‹) imgs/Chuo_01_Tokyo-St_up_20230201_knight/
        local  (str): ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ãƒ‘ã‚¹
                      (ä¾‹) ./
    """
    # S3ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    client  = boto3.client('s3')
    # ãƒã‚±ãƒƒãƒˆå
    bucket  = 'trolley-monitor'
    
    paginator = client.get_paginator('list_objects')
    for result in paginator.paginate(Bucket=bucket, Prefix=prefix):
        if result.get('Contents') is not None:
            for file in result.get('Contents'):
                if not os.path.exists(os.path.dirname(local + os.sep + file.get('Key'))):
                    os.makedirs(os.path.dirname(local + os.sep + file.get('Key')))
                client.download_file(bucket, file.get('Key'), local + os.sep + file.get('Key'))
        
    return


# S3ãƒã‚±ãƒƒãƒˆã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹
def put_s3_img(img, file_full_path):
    # imgã¯ã€Pillow Image.open()ã§èª­ã¿è¾¼ã¾ã‚ŒãŸå½¢å¼
    # ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹
    with BytesIO() as output:
        img.save(output, format="JPEG")
        contents = output.getvalue()
    s3 = boto3.client('s3')
    response = s3.put_object(Body=contents, Bucket='k-nagayama', Key=file_full_path)
    return


def imgs_dir_remove(path):
    """ pathã§æŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ã™ã‚‹
    Args:
        path (str): å‰Šé™¤ã—ãŸã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
    """
    try:
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãã®ä¸­èº«ã‚’ã™ã¹ã¦å‰Šé™¤
        shutil.rmtree(path)
    except FileNotFoundError:
        st.error("å¯¾è±¡ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    except Exception as e:
        print("An error occurred: ", e)
    return


# @st.cache()
def S3_EBS_imgs_dir_Compare(S3_dir_list, EBS_dir_list):
    """ 2ã¤ã®ãƒªã‚¹ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡ã‚’ã¾ã¨ã‚ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    Args:
        S3_dir_list (list): 1ã¤ç›®ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹ï¼‰S3å†…ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã®ãƒªã‚¹ãƒˆ
        EBS_dir_list (list): 2ã¤ç›®ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹ï¼‰EBSå†…ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã®ãƒªã‚¹ãƒˆ
    Return:
        df (DataFrame): çµæœã‚’ã¾ã¨ã‚ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    # ç·šåŒºåãƒªã‚¹ãƒˆã®ä½œæˆï¼ˆS3_dir_listã¨EBS_dir_listã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¦ç´ ã®åˆè¨ˆï¼‰
    line_names = list(set(S3_dir_list + EBS_dir_list))
    line_names.sort()

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
    df = pd.DataFrame(line_names, columns=['ç·šåŒºå'])

    # S3åˆ—ã¨TTSåˆ—ã®ä½œæˆ
    df['S3'] = df['ç·šåŒºå'].apply(lambda x: 'â—‹' if x in S3_dir_list else 'Ã—')
    df['TTSã‚·ã‚¹ãƒ†ãƒ '] = df['ç·šåŒºå'].apply(lambda x: 'â—‹' if x in EBS_dir_list else 'Ã—')

    return df


@st.cache()
def check_camera_dirs(dir_area, config):
    """ Outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®æœ‰ç„¡ã‚’ç¢ºèªã™ã‚‹
    Args:
        dir_area (str): outputå†…ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå
        config: configãƒ•ã‚¡ã‚¤ãƒ«
    Return:
        df (DataFrame): Pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å½¢å¼
    """
    # çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    result = []

    # å„ã‚«ãƒ¡ãƒ©ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯
    for camera_name, camera_type in config.camera_name_to_type.items():
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’ä½œæˆ
        dir_path = os.path.join(config.output_dir, dir_area, camera_type)
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
        try:
            for file in os.listdir(dir_path):
                if "rail.shelve" in file:  # ãƒ•ã‚¡ã‚¤ãƒ«åã«"rail.shelve"ãŒå«ã¾ã‚Œã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯
                    result.append([f"{camera_name}_{camera_type}", "â—‹"])
                    break
            else:  # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«"rail.shelve"ãŒå«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆ
                result.append([f"{camera_name}_{camera_type}", "Ã—"])
        except FileNotFoundError:  # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆ
            result.append([f"{camera_name}_{camera_type}", "Ã—"])

    # çµæœã‚’Pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
    df = pd.DataFrame(result, columns=["ã‚«ãƒ¡ãƒ©ç•ªå·", "çµæœæœ‰ç„¡"])

    return df


def check_camera_results(dir_area, config):
    """ Outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ï¼‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æœ‰ç„¡ã‚’ç¢ºèªã™ã‚‹
    Args:
        dir_area (str): outputå†…ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå
        config: configãƒ•ã‚¡ã‚¤ãƒ«
    Return:
        df (DataFrame): Pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å½¢å¼
    """
    # çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    result = []

    # å„ã‚«ãƒ¡ãƒ©ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯
    for camera_name, camera_type in config.camera_name_to_type.items():
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’ä½œæˆ
        dir_path = os.path.join(config.output_dir, dir_area, camera_type)
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
        try:
            shelve_check = False
            csv_check = False
            for file in os.listdir(dir_path):
                if "rail.shelve" in file:  # ãƒ•ã‚¡ã‚¤ãƒ«åã«"rail.shelve"ãŒå«ã¾ã‚Œã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯
                    shelve_check = True
                if file.endswith(".csv"):  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒCSVå½¢å¼ã‹ã‚’ãƒã‚§ãƒƒã‚¯
                    csv_check = True
                if shelve_check and csv_check:  # ä¸¡æ–¹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                    break
            result.append([f"{camera_name}_{camera_type}", "â—‹" if shelve_check else "Ã—", "â—‹" if csv_check else "Ã—"])
        except FileNotFoundError:  # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆ
            result.append([f"{camera_name}_{camera_type}", "Ã—", "Ã—"])

    # çµæœã‚’Pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
    df = pd.DataFrame(result, columns=["ã‚«ãƒ¡ãƒ©ç•ªå·", "çµæœæœ‰ç„¡", "CSVå¤‰æ›"])

    return df


def trim_trolley_dict(config, trolley_dict, img_path):
    """ shelveã‹ã‚‰èª­ã¿å–ã£ãŸtrolley_dictã®è¡Œæ•°ã‚’æƒãˆã‚‹
    Args:
        config: è¨­å®šç”¨ãƒ•ã‚¡ã‚¤ãƒ«
        trolley_dict(dict): shleveã‹ã‚‰èª­ã¿è¾¼ã‚“ã è¾æ›¸
        img_path(str): è§£æå¯¾è±¡ã®ç”»åƒãƒ‘ã‚¹
    Return:
        trolley_dict(dict): æ›´æ–°ã•ã‚ŒãŸtrolley_dict
    Memo:
        ãƒ‡ãƒãƒƒã‚°ç”¨ã®printæ–‡ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ã„ã¾ã™ã€‚
        å¿…è¦ãªå ´åˆã¯æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚
    """
    for trolley_id in config.trolley_ids:
        # print(trolley_id)
        for key in trolley_dict[img_path][trolley_id].keys():
            if not trolley_dict[img_path][trolley_id][key]:
                # ç©ºã®ãƒªã‚¹ãƒˆã®å ´åˆ
                # print("Empty list")
                trolley_dict[img_path][trolley_id][key] = [np.nan] * config.max_len
            # elif isinstance(trolley_dict[img_path][trolley_id][key], (int, float, str)):
            elif not isinstance(trolley_dict[img_path][trolley_id][key], list):
                # ãƒªã‚¹ãƒˆä»¥å¤–(æ•°å€¤ç­‰)ã®å ´åˆ
                # print("Not list")
                trolley_dict[img_path][trolley_id][key] = [trolley_dict[img_path][trolley_id][key]] + [np.nan] * (config.max_len - 1)
            value_len = len(trolley_dict[img_path][trolley_id][key])
            # print(f"{key} -> type: {type(trolley_dict[img_path][trolley_id][key])}, len:{value_len}")
            if config.max_len < value_len:
                config.max_len = value_len
        # print(f"Max Length: {config.max_len}")
    return trolley_dict


def read_trolley_dict(config, trolley_dict, img_path):
    """ ç”»åƒãƒ‘ã‚¹ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    Args:
        config: è¨­å®šç”¨ãƒ•ã‚¡ã‚¤ãƒ«
        trolley_dict(dict): shleveã‹ã‚‰èª­ã¿è¾¼ã‚“ã è¾æ›¸
        img_path(str): è§£æå¯¾è±¡ã®ç”»åƒãƒ‘ã‚¹
    Return:
        df_trolley(DataFrame): trolley_dictã‹ã‚‰ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    
    # trolley_dictã®è¡Œæ•°ã‚’æƒãˆã‚‹
    trim_trolley_dict(config, trolley_dict, img_path)
    
    df_trolley = pd.DataFrame()
    for idx, trolley_id in enumerate(config.trolley_ids):
        column_name = [trolley_id + "_" + key for key in list(trolley_dict[img_path][trolley_id].keys())]
        df = pd.DataFrame(trolley_dict[img_path][trolley_id]).copy()
        df.columns = column_name
        if not idx:
            df_trolley = df.copy()
            df_trolley = df_trolley.rename(columns={trolley_id + "_ix" : 'ix'})
        else:
            df_trolley = pd.concat([df_trolley, df], axis=1).copy()
    # èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ•´å½¢
    # trolleyX_ixã®åˆ—ã‚’å‰Šé™¤
    for col in df_trolley.columns:
        # åˆ—åã«'_ix'ãŒå«ã¾ã‚Œã‚‹å ´åˆ
        if '_ix' in col:
            # ãã®åˆ—ã‚’å‰Šé™¤
            df_trolley = df_trolley.drop(col, axis=1)
    # ç”»åƒåã‚’è¨˜éŒ²ã™ã‚‹
    if not "img_path" in df_trolley.columns:
        df_trolley.insert(0, 'img_path', img_path)
    else:
        df_trolley["img_path"] = img_path
    return df_trolley


def trolley_dict_to_csv(config, rail_fpath, camera_num, base_images):
    """ Shelveãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹
    Args:
        config: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
        rail_fpath (str): shelveãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ãƒ‘ã‚¹
        camera_num (str): é¸æŠã•ã‚ŒãŸã‚«ãƒ¡ãƒ©ç•ªå·
    """
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ãƒ‘ã‚¹ã‚’æŒ‡å®š
    csv_fpath = rail_fpath.replace(".shelve", ".csv")
    st.sidebar.write(f"csv_fpath:{csv_fpath}")

    # shelveãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    with shelve.open(rail_fpath) as rail:
        trolley_dict = copy.deepcopy(rail[camera_num])

    # èª­ã¿è¾¼ã‚“ã è¾æ›¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã™ã‚‹
    dfs = pd.DataFrame()
    for idx, img_path in enumerate(base_images):
        # print(f"{idx}> img_path: {img_path}")
        try:
            df_trolley = read_trolley_dict(config, trolley_dict, img_path).copy()
            # ixã®å€¤ãŒé€£ç•ªã«ãªã‚‹ã‚ˆã†ã«ä¿®æ­£
            df_trolley['ix'] = df_trolley['ix'] + 1000 * idx
            dfs = pd.concat([dfs, df_trolley], ignore_index=True)
        except Exception as e:
            st.sidebar.write(f"è§£æã‚¨ãƒ©ãƒ¼ã§ä¸­æ–­ã—ã¾ã—ãŸã€‚ä¸­æ–­ã—ãŸç”»åƒğŸ‘‡")
            st.sidebar.write(f"{idx}> img_path: {img_path}")
            # st.sidebar.error(f"Error> {e}")
            break
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¦outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ä¿å­˜ã™ã‚‹
    dfs.to_csv(csv_fpath, encoding='cp932')
    
    return


